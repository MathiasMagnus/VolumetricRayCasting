#include <QGenericMatrix>
#include "Scene.h"
#include  <algorithm>

#define _USE_MATH_DEFINES
#include <math.h>

using namespace std;

Scene::Scene()
{
	m_backgroundColor = QVector3D(0.0f, 0.0f, 0.0f); 
	m_light = Light(QVector3D(1.0f, 1.0f, 1.0f), QVector3D(0.0f, 4.0f, -1.0f));
	m_maxAccumulatedDensity = 0.0; 
}

void Scene::SetLimits(const std::array<std::array<float, 2>, 3 > &extent)
{
	m_minX = extent[0][0];
	m_maxX = extent[0][1];
	
	m_minY = extent[1][0];
	m_maxY = extent[1][1];
	
	m_minZ = extent[2][0];
	m_maxZ = extent[2][1];

	if (m_minX > m_maxX || m_minY > m_maxY || m_minZ > m_maxZ)
		throw std::runtime_error("Error: higher limit should be bigger than the lower!");

	// find center of the encapsulating sphere
	m_sphere.SetCenter(QVector3D((m_minX + m_maxX) / 2, (m_minY + m_maxY) / 2, (m_minZ + m_maxZ) / 2));
	float maxRadius = std::max({ (m_maxX - m_minX) , (m_maxY - m_minY) , (m_maxZ - m_minZ) }) / 2;
	m_sphere.SetRadius(maxRadius*1.8);

	m_deltaS = std::min({ (m_maxX - m_minX) , (m_maxY - m_minY) , (m_maxZ - m_minZ) }) / 100; //  step size
}

void Scene::Init(const QVector3D& cameraPosition, const QVector3D& viewedPosition, const float fieldOfView)
{
	m_camera.m_position = cameraPosition;
	m_camera.m_viewedPosition = viewedPosition;
	// The name direction vector is not the best chosen name, since it is actually pointing in the
	// reverse direction of what it is targeting.
	//m_camera.m_viewDir = QVector3D(m_camera.m_position - m_camera.m_viewedPosition); // this is the orig, for creating transform matrices
	m_camera.m_viewDir = QVector3D(m_camera.m_viewedPosition - m_camera.m_position);
	m_camera.m_viewDir.normalize();
	m_camera.m_viewUp = QVector3D(0.0, 1.0, 0.0);
	//m_camera.Orthonormalize();
	m_camera.m_fieldOfView = fieldOfView; // in degrees
	//CreateTransformMatrices();
}

void Scene::CreateTransformMatrices()
{
	/*
	float rotData[] = { m_camera.GetViewSide().x, m_camera.GetViewSide().y, m_camera.GetViewSide().z,
		m_camera.GetViewUp().x, m_camera.GetViewUp().y, m_camera.GetViewUp().z,
		m_camera.GetViewDir().x, m_camera.GetViewDir().y, m_camera.GetViewDir().z };
	QMatrix3x3 rotation3(rotData);
	//rotation3.SetRows(m_camera.GetViewSide(), m_camera.GetViewUp(), m_camera.GetViewDir());

	QMatrix4x4 rotation4;

	rotation4.Rotation(rotation3);


	QMatrix4x4 translation4;
	translation4.Identity();
	translation4.Translation(-m_camera.GetPosition());
	m_worldToViewMtx = rotation4 * translation4; // LookAtMatrix
	m_ViewToWorldMtx = AffineInverse(m_worldToViewMtx);
	*/
	m_worldToViewMtx.setToIdentity();
	m_ViewToWorldMtx.setToIdentity();
	m_worldToViewMtx.lookAt(m_camera.m_position, m_camera.m_viewedPosition, m_camera.m_viewUp);
	m_ViewToWorldMtx = m_worldToViewMtx.inverted();
}

void Scene::TransformToViewCoordinates(QVector3D & worldToViewCoord) const
{
	QVector4D  worldToViewCoord4(worldToViewCoord.x(), worldToViewCoord.y(), worldToViewCoord.z(), 1.0f);
	worldToViewCoord4 = m_worldToViewMtx * worldToViewCoord4;
	worldToViewCoord = QVector3D(worldToViewCoord4.x(), worldToViewCoord4.y(), worldToViewCoord4.z());
}

void Scene::TransformToWorldCoordinates(QVector3D & viewToWorldCoord) const
{
	QVector4D  viewToWorldCoord4(viewToWorldCoord.x(), viewToWorldCoord.y(), viewToWorldCoord.z(), 1.0f);
	viewToWorldCoord4 = m_ViewToWorldMtx * viewToWorldCoord4;
	viewToWorldCoord = QVector3D(viewToWorldCoord4.x(), viewToWorldCoord4.y(), viewToWorldCoord4.z());
}

//Initiate the volume rendering of the scene by raycasting/raymarching for each pixel
void Scene::Raycast()
{
	m_pixelColors.clear();
	m_pixelColors.reserve(WIDTH * HEIGHT);
	m_maxAccumulatedDensity = 0;
	CreateTransformMatrices();

	float aspectRatio = (float)WIDTH / (float)HEIGHT;
	float x, y, z;
	
	z = -1.0f;

	float scaleFOV = tan(m_camera.m_fieldOfView / 2 * M_PI / 180);

	for(unsigned int i=0; i < HEIGHT; i++)
	{	
		y = (1 - 2 * (i + 0.5) / (float)HEIGHT) * scaleFOV;
		for(unsigned int j=0; j < WIDTH; j++)
		{	
			x = (2 * (j + 0.5) / (float)WIDTH - 1) * aspectRatio * scaleFOV;
			QVector3D rayVec(x, y, z);

			float t0 = -1E+36;
			float t1 = -1E+36;
			
			/*
			// test ray
			rayVec.SetX(0.0);
			rayVec.SetY(0.0);
			rayVec.SetZ(-1.0);
			*/

			TransformToWorldCoordinates(rayVec);
			QVector3D transformedCamRayDir = rayVec - m_camera.GetPosition();
			transformedCamRayDir.normalize();
			bool bIntersected = m_sphere.GetIntersections(m_camera.GetPosition(), transformedCamRayDir, t0, t1);
			
			if (bIntersected && t0 > 0.0 && t1 > 0.0)
			{
				m_pixelColors.push_back(Raymarch(transformedCamRayDir, t0, t1));
			}
			// if we are inside the spehere, we trace from the the ray's original position
			else if (bIntersected && t1 > 0.0)   
			{
				m_pixelColors.push_back(Raymarch(transformedCamRayDir, 0.0, t1));
			}
			else
			{
				m_pixelColors.push_back(m_backgroundColor);
			}
		}
	}
}

//std::ofstream out("C:/Users/balaz/Google Drive/diplomamunka/Solutions/VolumeRendererSource/VolumeRenderer/loc2_00-1.txt");
//Raymarch from startT to endT, accumulating density
QVector3D Scene::Raymarch(const QVector3D& rayDirection, float startT, float endT)
{
	QVector3D color(0.0f, 0.0f, 0.0f);
	QVector3D location(0.0f, 0.0f, 0.0f);

	location = m_camera.GetPosition() + startT*rayDirection;

	float current_t = startT;
	float accumulatedDensity = 0.0;

	while(current_t < endT)
	{
		location = location + m_deltaS*rayDirection;
		current_t += m_deltaS;
		if (!IsOutside(location)) 
		{
			accumulatedDensity += m_densityFunc(location.x(), location.y(), location.z());
		}
	}
	
	if (accumulatedDensity > m_maxAccumulatedDensity) // needed for normalization
		m_maxAccumulatedDensity = accumulatedDensity;
	
	color = m_backgroundColor + accumulatedDensity * m_light.GetColor();
	return color;
}

bool Scene::IsOutside(const QVector3D& location) const
{
	float x = location.x();
	float y = location.y();
	float z = location.z();

	//if ((x >= m_maxX) || (y >= m_maxY) || (z > m_maxZ) || (x <= m_minX) || (y <= m_minY) || (z <= m_minZ))
	//	return true;

	if (x >= m_maxX)
		return true;
	else if (y >= m_maxY)
		return true;
	else if (z > m_maxZ)
		return true;
	else if (x <= m_minX)
		return true;
	else if (y <= m_minY)
		return true;
	else if (z <= m_minZ)
		return true;
	else
		return false;
}

//Scene::WriteImageFile
//Write array of pixel colors to bmp file
//std::ofstream outOfs("C:/Users/balaz/Desktop/VR_2/VolumeRenderer/rgb1.8_.txt");
void Scene::WriteImageFile(std::string filename)
{
	std::ostringstream out;
	out.clear();
	unsigned char r, g, b;
	for(unsigned int i = 0; i < m_pixelColors.size(); i++)
	{
		r = (unsigned char)(std::min(m_pixelColors[i].x() / m_maxAccumulatedDensity * 255., 255.));
		g = (unsigned char)(std::min(m_pixelColors[i].y() / m_maxAccumulatedDensity * 255., 255.));
		b = (unsigned char)(std::min(m_pixelColors[i].z() / m_maxAccumulatedDensity * 255., 255.));

		out << r << g << b;
		//outOfs << m_pixelColors[i].x() << " " << m_pixelColors[i].y() << " " << m_pixelColors[i].z() << std::endl;
	}
	out.flush();

	//SOIL_save_image(filename.c_str(), SOIL_SAVE_TYPE_BMP, WIDTH, HEIGHT, 3, (const unsigned char *)out.str().c_str());	
}

const std::vector<unsigned char> Scene::GetRGBData() const
{
	std::vector<unsigned char> rgbData;
	rgbData.reserve(m_pixelColors.size());
	unsigned char r, g, b;
	for (unsigned int i = 0; i < m_pixelColors.size(); i++)
	{
		r = (unsigned char)(std::min(m_pixelColors[i].x() / m_maxAccumulatedDensity * 255., 255.));
		g = (unsigned char)(std::min(m_pixelColors[i].y() / m_maxAccumulatedDensity * 255., 255.));
		b = (unsigned char)(std::min(m_pixelColors[i].z() / m_maxAccumulatedDensity * 255., 255.));

		//out << r << g << b;
		rgbData.push_back(r);
		rgbData.push_back(g);
		rgbData.push_back(b);
		//outOfs << m_pixelColors[i].x() << " " << m_pixelColors[i].y() << " " << m_pixelColors[i].z() << std::endl;
	}

	return rgbData;
}

QVector3D Scene::GetCameraPos() const
{
	return m_camera.GetPosition();
}

QVector3D Scene::GetCameraViewDir() const
{
	return m_camera.GetViewDir();
}
void Scene::SetCameraPos(const QVector3D &cameraPos)
{
	m_camera.SetPosition(cameraPos);
}
